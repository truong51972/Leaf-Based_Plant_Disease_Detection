{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1918c046-08b5-40c8-b229-0fba7db05f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from torchmetrics.classification import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "404b026b-f2b6-405d-8a2b-fadc345fb125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b482125-f098-4e26-86fb-d95c0f6eae64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/data_setup.py\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from pathlib import Path\n",
    "\"\"\"\n",
    "Contain for setting updata with full func to create dataloader\n",
    "\"\"\"\n",
    "\n",
    "def create_dataloader(\n",
    "                    dataset_path: Path,\n",
    "                    batch_size: int,\n",
    "                    train_transform: transforms.Compose,\n",
    "                    val_transform: transforms.Compose,\n",
    "                ):\n",
    "    train_path = dataset_path / 'train'\n",
    "    val_path = dataset_path / 'val'\n",
    "    \n",
    "    train_data = ImageFolder(\n",
    "        root= train_path,\n",
    "        transform= train_transform\n",
    "    )\n",
    "    \n",
    "    val_data = ImageFolder(\n",
    "        root= val_path,\n",
    "        transform= val_transform\n",
    "    )\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        dataset= train_data,\n",
    "        batch_size= batch_size,\n",
    "        shuffle= True\n",
    "    )\n",
    "    \n",
    "    val_dataloader = DataLoader(\n",
    "        dataset= val_data,\n",
    "        batch_size= batch_size,\n",
    "        shuffle= False\n",
    "    )\n",
    "    \n",
    "    class_names = train_data.classes\n",
    "    return train_dataloader, val_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c359100c-6a05-4415-bf09-cf9d09ac6d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/model_builder.py\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "def efficientnet_v2_s_model(class_names: list, device: str):\n",
    "    weights = EfficientNet_V2_S_Weights.DEFAULT\n",
    "    model = efficientnet_v2_s(weights= weights)\n",
    "\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(in_features=1280, out_features=len(class_names), bias=True)\n",
    "    )\n",
    "\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def resnet50_model(class_names: list, device: str):\n",
    "    weights = ResNet50_Weights.DEFAULT\n",
    "    model = resnet50(weights= weights).to(device)\n",
    "\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(in_features=2048, out_features=len(class_names), bias=True)\n",
    "    )\n",
    "\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b43658f-e780-4fd7-8ed7-cfeb20ee930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.models import resnet50, ResNet50_Weights\n",
    "# from torchinfo import summary\n",
    "\n",
    "# summary(model=resnet50(), \n",
    "#         input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
    "#         # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "#         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#         col_width=20,\n",
    "#         row_settings=[\"var_names\"]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3485baaf-1bfd-4187-beab-6794b58ead3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50().fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b7ee938-113a-465c-9f6a-bf4c62674528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/utils.py\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def plot_loss_curves(results: dict[str, list[float]]):\n",
    "    \n",
    "    # Get the loss values of the results dictionary (training and val)\n",
    "    train_loss = results['train_loss']\n",
    "    val_loss = results['val_loss']\n",
    "    # Get the accuracy values of the results dictionary (training and val)\n",
    "    train_accuracy = results['train_acc']\n",
    "    val_accuracy = results['val_acc']\n",
    "\n",
    "    # Figure out how many epochs there were\n",
    "    epochs = range(len(results['train_loss']))\n",
    "\n",
    "    # Setup a plot \n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_loss, label='train_loss')\n",
    "    plt.plot(epochs, val_loss, label='val_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accuracy, label='train_accuracy')\n",
    "    plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig('haha.png')\n",
    "    return plt\n",
    "\n",
    "def save_model(model: torch.nn.Module,\n",
    "               results: dict[str, list[float]]):\n",
    "    \n",
    "    graph = plot_loss_curves(results)\n",
    "    \n",
    "    target_dir = Path('runs/classify/')\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    model_name = 'model.pth'\n",
    "    graph_name = 'loss.jpg'\n",
    "    \n",
    "    train_paths = os.listdir(target_dir)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while True:\n",
    "        train_path = f'train{i}'\n",
    "        if train_path not in train_paths:\n",
    "            break\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    target_dir = target_dir / train_path\n",
    "    \n",
    "    target_dir_path = Path(target_dir)\n",
    "    target_dir_path.mkdir(parents=True,exist_ok=True)\n",
    "    \n",
    "    model_save_path = target_dir_path / model_name\n",
    "    graph_save_path = target_dir_path / graph_name\n",
    "    \n",
    "    print(f\"[INFO] Saving model to: {target_dir}\")\n",
    "    graph.savefig(graph_save_path)\n",
    "    torch.save(obj=model.state_dict(), f=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e06eca4-adf7-4d57-b122-1ce232052503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/engine.py\n",
    "import torch\n",
    "from torchmetrics import Accuracy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def __train(model: torch.nn.Module,\n",
    "            dataloader: torch.utils.data.DataLoader,\n",
    "            loss_func: torch.nn.Module,\n",
    "            optimizer: torch.optim.Optimizer,\n",
    "            mectric_func: Accuracy,\n",
    "            device: str):\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for _, (X, y) in enumerate(tqdm(dataloader, desc= '-----Train')):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        y_pred = model(X)\n",
    "        loss = loss_func(y_pred, y)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim= 1), dim= 1)\n",
    "        train_acc += mectric_func(y_pred, y).item()\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "    \n",
    "    return train_loss, train_acc\n",
    "\n",
    "def __val(model: torch.nn.Module,\n",
    "           dataloader: torch.utils.data.DataLoader,\n",
    "           loss_func: torch.nn.Module,\n",
    "           mectric_func: Accuracy,\n",
    "           device: str):\n",
    "\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for _, (X, y) in enumerate(tqdm(dataloader, desc= '-------Val')):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            y_pred = model(X)\n",
    "            loss = loss_func(y_pred, y)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            y_pred_class = torch.argmax(torch.softmax(y_pred, dim= 1), dim= 1)\n",
    "            val_acc += mectric_func(y_pred, y).item()\n",
    "\n",
    "        val_loss /= len(dataloader)\n",
    "        val_acc /= len(dataloader)\n",
    "\n",
    "    return val_loss, val_acc\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          val_dataloader: torch.utils.data.DataLoader,\n",
    "          loss_func: torch.nn.Module,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          mectric_func: Accuracy,\n",
    "          epochs: int,\n",
    "          device: str):\n",
    "    \n",
    "    results = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],    \n",
    "    }\n",
    "    \n",
    "    torch.manual_seed(42) \n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc= 'Epoch'):\n",
    "        print(f\"\\n\\nEpoch: {epoch+1:2} ------------\")\n",
    "        train_loss, train_acc = __train(model=model,\n",
    "                                        dataloader=train_dataloader,\n",
    "                                        loss_func=loss_func,\n",
    "                                        optimizer=optimizer,\n",
    "                                        mectric_func=mectric_func,\n",
    "                                        device= device)\n",
    "        \n",
    "        val_loss, val_acc = __val(model=model,\n",
    "                                dataloader=val_dataloader,\n",
    "                                loss_func=loss_func,\n",
    "                                mectric_func=mectric_func,\n",
    "                                device= device)\n",
    "        \n",
    "        print(f\"Epoch: {epoch+1:2} | Train Loss: {train_loss:.5f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.5f} | Val Acc: {val_acc:.4f}\")\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"val_loss\"].append(val_loss)\n",
    "        results[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c48a854-20c5-4a0a-b2e8-fd24e14989fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/train.py\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "from pathlib import Path\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from model.data_setup import create_dataloader\n",
    "from model.engine import train\n",
    "from model.utils import save_model\n",
    "from model.model_builder import resnet50_model\n",
    "\n",
    "def run(dataset_path: str= 'path_to_dataset', epoch:int= 25, learning_rate: float= 0.001, batch_size: int= 32):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    dataset_path = Path(dataset_path)\n",
    "    \n",
    "    train_transforms_data = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=(224, 224), antialias=True),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    val_transforms_data = transforms.Compose([\n",
    "        transforms.Resize(size= 224),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_dataloader, val_dataloader, class_names = create_dataloader(dataset_path=dataset_path,\n",
    "                                                              batch_size=batch_size,\n",
    "                                                              train_transform=train_transforms_data,\n",
    "                                                              val_transform=val_transforms_data)\n",
    "\n",
    "\n",
    "    model = resnet50_model(class_names= class_names, device= device)\n",
    "    \n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(params= model.parameters(), lr= learning_rate)\n",
    "    \n",
    "    mectric_func = Accuracy(task='multiclass', num_classes= len(class_names)).to(device)\n",
    "    \n",
    "    results = train(\n",
    "            model= model,\n",
    "            train_dataloader= train_dataloader,\n",
    "            val_dataloader= val_dataloader,\n",
    "            loss_func= loss_func,\n",
    "            optimizer= optimizer,\n",
    "            mectric_func= mectric_func,\n",
    "            epochs= epoch,\n",
    "            device= device\n",
    "    )\n",
    "\n",
    "    save_model(model= model, results= results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8345f941-bdbd-4d02-83db-2c6f90942dba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570dc4b79099497c8017de051adb0594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch:  1 ------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70588b94a28548d2a587c4ea27800550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-----Train:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120785acf7074bfa8af6702db2efc27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-------Val:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 | Train Loss: 2.24206 | Train Acc: 0.2149 | Val Loss: 2.19557 | Val Acc: 0.3389\n",
      "\n",
      "\n",
      "Epoch:  2 ------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53e25c41bbb4daeb55e08c1ec90af6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-----Train:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model import train\n",
    "\n",
    "train.run(dataset_path='./datasets/tomato', epoch= 2, batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdb61fd-6fdf-41d4-9d5d-8cb71e3ec8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
